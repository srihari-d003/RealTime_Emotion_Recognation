{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35530,"status":"ok","timestamp":1749522431040,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"},"user_tz":-330},"id":"R9OK-16WsqvX","outputId":"41490a09-c5d8-4b98-b12e-2b1229f41d7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":155,"status":"error","timestamp":1749528205663,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"},"user_tz":-330},"id":"XuJ-txYDs1SL","outputId":"45dbb7ff-add4-4df8-fc65-32f8e8855220"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/ML_Projects/fer2013.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b773098706f2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ML_Projects/fer2013.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load and preprocess the dataset (use FER-2013 or similar facial expression datasets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/ML_Projects/fer2013.csv'"]}],"source":["import pandas as pd\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","real = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","\n","# Load and preprocess the dataset (use FER-2013 or similar facial expression datasets)\n","def load_dataset():\n","    # Assuming FER-2013 dataset or similar format with \"pixels\" and \"emotion\" columns\n","    import pandas as pd\n","\n","    data = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","    X = []\n","    y = []\n","    for i in range(len(data)):\n","        pixels = np.array(data['pixels'][i].split(), dtype='float32').reshape(48, 48)\n","        X.append(pixels)\n","        y.append(data['emotion'][i])\n","    X = np.array(X)\n","    y = np.array(y)\n","    X = X / 255.0  # Normalize pixel values\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","real = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","\n","# Load and preprocess the dataset (use FER-2013 or similar facial expression datasets)\n","def load_dataset():\n","    # Assuming FER-2013 dataset or similar format with \"pixels\" and \"emotion\" columns\n","    import pandas as pd\n","\n","    data = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","    X = []\n","    y = []\n","    for i in range(len(data)):\n","        pixels = np.array(data['pixels'][i].split(), dtype='float32').reshape(48, 48)\n","        X.append(pixels)\n","        y.append(data['emotion'][i])\n","    X = np.array(X)\n","    y = np.array(y)\n","    X = X / 255.0  # Normalize pixel values\n","    y = to_categorical(y)  # One-hot encode emotion labels\n","    return X, y\n","real.head()"]},{"source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# %%\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","# Load and preprocess the dataset (use FER-2013 or similar facial expression datasets)\n","def load_dataset():\n","    # Assuming FER-2013 dataset or similar format with \"pixels\" and \"emotion\" columns\n","    import pandas as pd\n","\n","    # Verify the file path after mounting the drive\n","    data = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","    X = []\n","    y = []\n","    for i in range(len(data)):\n","        pixels = np.array(data['pixels'][i].split(), dtype='float32').reshape(48, 48)\n","        X.append(pixels)\n","        y.append(data['emotion'][i])\n","    X = np.array(X)\n","    y = np.array(y)\n","    X = X / 255.0  # Normalize pixel values\n","    y = to_categorical(y)  # One-hot encode emotion labels\n","    return X, y\n","\n","# Load the dataset outside the function for initial verification and head() call\n","real = pd.read_csv('/content/drive/My Drive/ML_Projects/fer2013.csv')\n","real.head()\n","\n","# %%\n","\n","# Build the CNN model\n","def build_model(input_shape):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.5),\n","        Dense(7, activation='softmax')  # Assuming 7 emotion classes\n","    ])\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Train and evaluate the model\n","def train_model(X, y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = build_model((48, 48, 1))\n","    model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_test, y_test))\n","    return model, X_test, y_test\n","\n","# Real-time emotion detection with webcam\n","def emotion_detection(model):\n","    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","    cap = cv2.VideoCapture(0)\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","        detected_faces = faces.detectMultiScale(gray, 1.3, 5)\n","\n","        for (x, y, w, h) in detected_faces:\n","            roi = gray[y:y+h, x:x+w]\n","            roi = cv2.resize(roi, (48, 48))\n","            roi = roi.reshape(1, 48, 48, 1) / 255.0\n","            prediction = model.predict(roi)\n","            emotion = emotion_labels[np.argmax(prediction)]\n","            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n","            cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","        cv2.imshow('Emotion Detection', frame)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","# Main function\n","if __name__ == \"__main__\":\n","    X, y = load_dataset()\n","    X = X.reshape(-1, 48, 48, 1)  # Reshape for CNN\n","    model, X_test, y_test = train_model(X, y)\n","    print(\"Model trained successfully. Starting real-time emotion detection.\")\n","    emotion_detection(model)\n","\n","# %%\n","from IPython.display import display, Javascript\n","\n","# JavaScript function to capture a photo from the webcam\n","def take_photo():\n","    js_code = \"\"\"\n","        async function takePhoto() {\n","            const video = document.createElement('video');\n","            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n","\n","            video.srcObject = stream;\n","            await new Promise((resolve) => video.onloadedmetadata = resolve);\n","            video.play();\n","\n","            await new Promise((resolve) => setTimeout(resolve, 1000));\n","\n","            const canvas = document.createElement('canvas');\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            canvas.getContext('2d').drawImage(video, 0, 0);\n","            stream.getTracks().forEach(track => track.stop());\n","\n","            return canvas.toDataURL('image/jpeg', 0.8);\n","        }\n","        google.colab.kernel.invokeFunction('notebook.capture_photo', [], {});\n","    \"\"\"\n","    display(Javascript(js_code))\n","# %%\n","from google.colab.output import eval_js\n","import numpy as np\n","import cv2\n","import base64\n","\n","# Function to convert JavaScript image to OpenCV format\n","def js_to_image(js_reply):\n","    image_bytes = base64.b64decode(js_reply.split(',')[1])  # Decode base64 image\n","    nparr = np.frombuffer(image_bytes, np.uint8)\n","    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","    return img\n","\n","# Display JavaScript to capture image\n","take_photo()  # Ensure JavaScript function is available\n","\n","# Wait and then capture the frame\n","photo_data = eval_js(\"takePhoto()\")  # Trigger JavaScript function\n","captured_frame = js_to_image(photo_data)  # Convert image to OpenCV format\n","\n","# Verify if frame is captured\n","if captured_frame is None:\n","    print(\"Error: Could not capture frame.\")\n","else:\n","    print(\"Frame captured successfully!\")\n","# %%\n","from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","model=load_model('/content/drive/My Drive/Colab Notebooks/cnn_model.keras')\n","# Function to preprocess the captured frame for emotion detection\n","def preprocess_frame(frame):\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n","    gray = cv2.resize(gray, (48, 48))  # Resize to 48x48 (input size of model)\n","    gray = gray.reshape(1, 48, 48, 1) / 255.0  # Normalize and reshape for model\n","    return gray\n","\n","# Function to predict emotion from the frame using the trained model\n","def predict_emotion(frame, model):\n","    preprocessed_frame = preprocess_frame(frame)  # Preprocess the frame\n","    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","\n","    # Predict the emotion using the model\n","    prediction = model.predict(preprocessed_frame)\n","    emotion = emotion_labels[np.argmax(prediction)]  # Get the emotion with the highest probability\n","\n","    return emotion\n","\n","# Function to draw the emotion label on the frame (optional: face detection)\n","def draw_results(frame, emotion, x, y, w, h):\n","    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw rectangle around face\n","    cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)  # Draw emotion label\n","    return frame\n","\n","# Assuming captured_frame is the captured image from the webcam\n","captured_frame = js_to_image(photo_data)  # Convert the captured frame from JavaScript\n","\n","# Detect faces in the captured frame (you may use OpenCV's face detection for this)\n","faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(captured_frame, 1.3, 5)\n","\n","# Process each detected face\n","for (x, y, w, h) in faces:\n","    face = captured_frame[y:y + h, x:x + w]  # Crop the face region\n","\n","    # Predict the emotion for the detected face\n","    emotion = predict_emotion(face, model)\n","\n","    # Draw the result on the captured frame (bounding box + emotion label)\n","    captured_frame = draw_results(captured_frame, emotion, x, y, w, h)\n","\n","# Display the processed image with emotion label (in Colab)\n","from google.colab.patches import cv2_imshow\n","cv2_imshow(captured_frame)\n","\n","# Optionally, save the processed image\n","cv2.imwrite(\"emotion_detected.jpg\", captured_frame)\n","\n","# Confirmation message\n","print(\"Emotion detected and image displayed successfully!\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"MiiwMmF0Aq4c","executionInfo":{"status":"error","timestamp":1749528283018,"user_tz":-330,"elapsed":3894,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"}},"outputId":"9a754265-a105-4fe0-b193-43bf69c61310"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/ML_Projects/fer2013.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-821ac601250c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Load the dataset outside the function for initial verification and head() call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ML_Projects/fer2013.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/ML_Projects/fer2013.csv'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JeIhJh9MuJ79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Build the CNN model\n","def build_model(input_shape):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.5),\n","        Dense(7, activation='softmax')  # Assuming 7 emotion classes\n","    ])\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Train and evaluate the model\n","def train_model(X, y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = build_model((48, 48, 1))\n","    model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data=(X_test, y_test))\n","    return model, X_test, y_test\n","\n","# Real-time emotion detection with webcam\n","def emotion_detection(model):\n","    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","    cap = cv2.VideoCapture(0)\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","        detected_faces = faces.detectMultiScale(gray, 1.3, 5)\n","\n","        for (x, y, w, h) in detected_faces:\n","            roi = gray[y:y+h, x:x+w]\n","            roi = cv2.resize(roi, (48, 48))\n","            roi = roi.reshape(1, 48, 48, 1) / 255.0\n","            prediction = model.predict(roi)\n","            emotion = emotion_labels[np.argmax(prediction)]\n","            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n","            cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","        cv2.imshow('Emotion Detection', frame)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","# Main function\n","if __name__ == \"__main__\":\n","    X, y = load_dataset()\n","    X = X.reshape(-1, 48, 48, 1)  # Reshape for CNN\n","    model, X_test, y_test = train_model(X, y)\n","    print(\"Model trained successfully. Starting real-time emotion detection.\")\n","    emotion_detection(model)\n"],"metadata":{"id":"bRs2_3tKPZTX","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1749525444848,"user_tz":-330,"elapsed":269,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"}},"outputId":"fa7d76b5-0438-4c6a-c46f-8895ccb5721a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/fer2013/fer2013.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-deb67073034f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape for CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-c61a92cee8a5>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fer2013.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/fer2013/fer2013.csv'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnEk38XL-y4Z"},"outputs":[],"source":["from IPython.display import display, Javascript\n","\n","# JavaScript function to capture a photo from the webcam\n","def take_photo():\n","    js_code = \"\"\"\n","        async function takePhoto() {\n","            const video = document.createElement('video');\n","            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n","\n","            video.srcObject = stream;\n","            await new Promise((resolve) => video.onloadedmetadata = resolve);\n","            video.play();\n","\n","            await new Promise((resolve) => setTimeout(resolve, 1000));\n","\n","            const canvas = document.createElement('canvas');\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            canvas.getContext('2d').drawImage(video, 0, 0);\n","            stream.getTracks().forEach(track => track.stop());\n","\n","            return canvas.toDataURL('image/jpeg', 0.8);\n","        }\n","        google.colab.kernel.invokeFunction('notebook.capture_photo', [], {});\n","    \"\"\"\n","    display(Javascript(js_code))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":9856,"status":"ok","timestamp":1746727993943,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"},"user_tz":-330},"id":"wPN68j2v-2qS","outputId":"fa47123c-e58b-41fd-fb9f-9bf9b9b4ef4c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        async function takePhoto() {\n","            const video = document.createElement('video');\n","            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n","\n","            video.srcObject = stream;\n","            await new Promise((resolve) => video.onloadedmetadata = resolve);\n","            video.play();\n","\n","            await new Promise((resolve) => setTimeout(resolve, 1000));\n","\n","            const canvas = document.createElement('canvas');\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            canvas.getContext('2d').drawImage(video, 0, 0);\n","            stream.getTracks().forEach(track => track.stop());\n","\n","            return canvas.toDataURL('image/jpeg', 0.8);\n","        }\n","        google.colab.kernel.invokeFunction('notebook.capture_photo', [], {});\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Frame captured successfully!\n"]}],"source":["from google.colab.output import eval_js\n","import numpy as np\n","import cv2\n","import base64\n","\n","# Function to convert JavaScript image to OpenCV format\n","def js_to_image(js_reply):\n","    image_bytes = base64.b64decode(js_reply.split(',')[1])  # Decode base64 image\n","    nparr = np.frombuffer(image_bytes, np.uint8)\n","    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n","    return img\n","\n","# Display JavaScript to capture image\n","take_photo()  # Ensure JavaScript function is available\n","\n","# Wait and then capture the frame\n","photo_data = eval_js(\"takePhoto()\")  # Trigger JavaScript function\n","captured_frame = js_to_image(photo_data)  # Convert image to OpenCV format\n","\n","# Verify if frame is captured\n","if captured_frame is None:\n","    print(\"Error: Could not capture frame.\")\n","else:\n","    print(\"Frame captured successfully!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":682},"executionInfo":{"elapsed":79,"status":"error","timestamp":1746727999481,"user":{"displayName":"TEJAVATH SHARATH RGUKT Basar","userId":"07298739161974269482"},"user_tz":-330},"id":"uT7dB3quAZw_","outputId":"b4e95b8e-34aa-496f-b224-046131327bd6"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"File not found: filepath=/content/drive/My Drive/Colab Notebooks/cnn_model.keras. Please ensure the file is an accessible `.keras` zip file.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-93db5b14aa7b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/cnn_model.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Function to preprocess the captured frame for emotion detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: File not found: filepath=/content/drive/My Drive/Colab Notebooks/cnn_model.keras. Please ensure the file is an accessible `.keras` zip file."]}],"source":["from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","model=load_model('/content/drive/My Drive/Colab Notebooks/cnn_model.keras')\n","# Function to preprocess the captured frame for emotion detection\n","def preprocess_frame(frame):\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n","    gray = cv2.resize(gray, (48, 48))  # Resize to 48x48 (input size of model)\n","    gray = gray.reshape(1, 48, 48, 1) / 255.0  # Normalize and reshape for model\n","    return gray\n","\n","# Function to predict emotion from the frame using the trained model\n","def predict_emotion(frame, model):\n","    preprocessed_frame = preprocess_frame(frame)  # Preprocess the frame\n","    emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","\n","    # Predict the emotion using the model\n","    prediction = model.predict(preprocessed_frame)\n","    emotion = emotion_labels[np.argmax(prediction)]  # Get the emotion with the highest probability\n","\n","    return emotion\n","\n","# Function to draw the emotion label on the frame (optional: face detection)\n","def draw_results(frame, emotion, x, y, w, h):\n","    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw rectangle around face\n","    cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)  # Draw emotion label\n","    return frame\n","\n","# Assuming captured_frame is the captured image from the webcam\n","captured_frame = js_to_image(photo_data)  # Convert the captured frame from JavaScript\n","\n","# Detect faces in the captured frame (you may use OpenCV's face detection for this)\n","faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(captured_frame, 1.3, 5)\n","\n","# Process each detected face\n","for (x, y, w, h) in faces:\n","    face = captured_frame[y:y + h, x:x + w]  # Crop the face region\n","\n","    # Predict the emotion for the detected face\n","    emotion = predict_emotion(face, model)\n","\n","    # Draw the result on the captured frame (bounding box + emotion label)\n","    captured_frame = draw_results(captured_frame, emotion, x, y, w, h)\n","\n","# Display the processed image with emotion label (in Colab)\n","from google.colab.patches import cv2_imshow\n","cv2_imshow(captured_frame)\n","\n","# Optionally, save the processed image\n","cv2.imwrite(\"emotion_detected.jpg\", captured_frame)\n","\n","# Confirmation message\n","print(\"Emotion detected and image displayed successfully!\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}